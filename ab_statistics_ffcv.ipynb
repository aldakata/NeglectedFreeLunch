{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.fields.decoders import NDArrayDecoder, IntDecoder\n",
    "from ffcv.fields import NDArrayField\n",
    "import csv\n",
    "\n",
    "class StringDecoder(NDArrayDecoder):\n",
    "    pass\n",
    "class StringField(NDArrayField):\n",
    "    def __init__(self, max_len: int, pad_char='\\0'):\n",
    "        self.max_len = max_len\n",
    "        self.pad_char = pad_char\n",
    "        super().__init__(np.dtype('uint8'), (max_len,))\n",
    "    \n",
    "    def encode(self, destination, field, malloc):\n",
    "        padded_field = (field + self.pad_char * self.max_len)[:self.max_len]\n",
    "        field = np.frombuffer(padded_field.encode('ascii'), dtype='uint8')\n",
    "        return super().encode(destination, field, malloc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports finished\n"
     ]
    }
   ],
   "source": [
    "path = \"/mnt/qb/work/oh/owl156/imagenet_AB_train_500_0.5_90.ffcv\"\n",
    "PIPELINES = {\n",
    "        'selected': [IntDecoder()],\n",
    "        'estimateTime': [IntDecoder()],\n",
    "        'worker_id': [StringDecoder()],\n",
    "        'assignment_id': [StringDecoder()],\n",
    "        }\n",
    "\n",
    "loader = Loader(path,\n",
    "        batch_size=1,\n",
    "        num_workers = 2,\n",
    "        order=OrderOption.SEQUENTIAL,\n",
    "        pipelines=PIPELINES,\n",
    "        custom_fields={\n",
    "                    'worker_id': StringField,\n",
    "                    'assignment_id': StringField\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1281167 [00:09<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "iterator = tqdm(loader)\n",
    "e = enumerate(iterator)\n",
    "el = next(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, (image, label, weight, loc_info, selected_record, selected_record_time, selected, estimateTime, worker_id, assignment_id) = el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tqdm(loader)\n",
    "not_selected = []\n",
    "worker_sum = {}\n",
    "worker_min = {}\n",
    "worker_max = {}\n",
    "worker_counts = {}\n",
    "\n",
    "print('Loop')\n",
    "for i, (_, _, _, _, _, _, selected, estimateTime, workerid, assignmentid) in enumerate(iterator):\n",
    "    workerid=workerid.tobytes().decode('ascii').replace('\\0', '')\n",
    "    if workerid not in worker_sum.keys():\n",
    "        worker_sum[workerid] = estimateTime \n",
    "        worker_min[workerid] = estimateTime\n",
    "        worker_max[workerid] = estimateTime \n",
    "        worker_counts[workerid] = 1 \n",
    "    else:\n",
    "        worker_sum[workerid] += estimateTime\n",
    "        if worker_min[workerid] > estimateTime:\n",
    "            worker_min[workerid] = estimateTime\n",
    "        if worker_min[workerid] < estimateTime:\n",
    "            worker_max[workerid] = estimateTime \n",
    "        worker_counts[workerid] += 1\n",
    "\n",
    "    if not i%10000:\n",
    "        print(f\"item {i} covariate {selected}, label {estimateTime}, workerid {workerid}, assignmentid {assignmentid}, Number of workers so Far{len(worker_min)}\")\n",
    "    if not selected == 1:\n",
    "        not_selected.append(i)\n",
    "\n",
    "# Save the indices of the elements to ignore\n",
    "np.save('not_selected.npy', np.asarray(not_selected))\n",
    "\n",
    "with open('writer_statistics.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(['writer_id', 'estimated_time_avg', 'estimated_time_max', 'estimated_time_min'])\n",
    "\n",
    "    for key in worker_counts.keys():\n",
    "        writer_id= worker_sum[key]   \n",
    "        estimated_time_avg= worker_min[key]  \n",
    "        estimated_time_max= worker_max[key]  \n",
    "        estimated_time_min= worker_counts[key]  \n",
    "        writer.writerow([f'{writer_id}', f'{estimated_time_avg}', f'{estimated_time_max}', f'{estimated_time_min}'])\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
